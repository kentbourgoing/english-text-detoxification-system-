{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1rhtOAceoHn"
   },
   "source": [
    "# T5-ParaDetox Pipeline with DecompX Reranking\n",
    "\n",
    "This notebook combines:\n",
    "- **T5-base** fine-tuned on ParaDetox for detoxification\n",
    "- **DecompX reranking** to select the least toxic candidate from multiple generations\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "1. Generate `num_candidates` detoxified texts per input using T5 sampling\n",
    "2. Score each candidate using DecompX toxicity attribution (RoBERTa-based)\n",
    "3. Select candidate with lowest toxicity score\n",
    "4. Evaluate with BLEU, BERTScore, MeaningBERT, Perplexity, Toxicity\n",
    "\n",
    "---\n",
    "\n",
    "## `detoxify()` API\n",
    "\n",
    "```python\n",
    "def detoxify(\n",
    "    data_type: str = \"paradetox\",\n",
    "    output_folder: str = \"T5_w_DecompX-Reranking\",\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 128,\n",
    "    num_examples: int = 100,\n",
    "    num_candidates: int = 10,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = 50,\n",
    "    top_p: float = 0.95,\n",
    "    overwrite_gen: bool = False,\n",
    "    run_eval: bool = True,\n",
    "    overwrite_eval: bool = False,\n",
    "    echo: bool = False,\n",
    ")\n",
    "```\n",
    "\n",
    "### Key Arguments\n",
    "\n",
    "- `data_type`: Dataset key (paradetox, microagressions_test, sbf_test, dynabench_test, jigsaw_toxic, appdia_original, appdia_discourse)\n",
    "- `output_folder`: Folder under `data/model_outputs/` for results\n",
    "- `num_candidates`: Number of candidates to generate per input for reranking\n",
    "- `temperature`: Sampling temperature for diversity (higher = more diverse)\n",
    "- `echo`: If True, print example inputs, candidates, and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYc9JrJaeoHp"
   },
   "source": "## setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4W_N0aereoHp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843405675,
     "user_tz": 480,
     "elapsed": 39736,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "a7cc48f6-d8d0-4302-a3c9-0d988cfe40fe"
   },
   "outputs": [],
   "source": "from google.colab import drive; drive.mount('/content/drive')\n\nimport os, sys, torch\n\nPROJECT_BASE = \"/content/drive/MyDrive/w266 - Project\"\nXDETOX_DIR   = os.path.join(PROJECT_BASE, \"XDetox\")\nT5_CHECKPOINT = os.path.join(PROJECT_BASE, \"t5-base-detox-model\")\n\nprint(\"project:\", PROJECT_BASE)\nprint(\"xdetox:\", XDETOX_DIR, \"->\", os.path.isdir(XDETOX_DIR))\nprint(\"ckpt:\", T5_CHECKPOINT)\n\nassert os.path.isdir(XDETOX_DIR), f\"missing: {XDETOX_DIR}\"\n\nHF_CACHE = os.path.join(XDETOX_DIR, \"cache\")\nos.makedirs(HF_CACHE, exist_ok=True)\nos.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nif XDETOX_DIR not in sys.path:\n    sys.path.append(XDETOX_DIR)\n\nprint(\"cache:\", HF_CACHE)\nprint(\"cuda:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"gpu:\", torch.cuda.get_device_name(0))"
  },
  {
   "cell_type": "code",
   "source": "for d in [\"rewrite\", \"evaluation\", \"datasets\", \"data\"]:\n    assert os.path.isdir(os.path.join(XDETOX_DIR, d)), f\"missing: {d}\"\nprint(\"folders ok\")\n\nREPO = XDETOX_DIR\nDATASET_BASE = REPO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1kyTe1yzOgQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843405720,
     "user_tz": 480,
     "elapsed": 17,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "750c2e2f-63d0-44ed-fe87-72cfcca5a777"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUMJhQb_eoHq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843440847,
     "user_tz": 480,
     "elapsed": 35125,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "756442d3-c825-40b4-aaf2-c69c53627a0c"
   },
   "outputs": [],
   "source": "!pip -q install --upgrade pip setuptools wheel\n!pip -q install \"transformers==4.41.2\" \"tokenizers==0.19.1\" \\\n                \"datasets==2.19.0\" \"evaluate==0.4.1\" \\\n                \"sacrebleu==2.4.1\" sacremoses ftfy nltk matplotlib pandas jedi \\\n                sentencepiece\n!pip -q install bert-score"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGDUUoabeoHr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843451323,
     "user_tz": 480,
     "elapsed": 10470,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "f75580f1-d2c3-48e5-c949-0834b80a156a"
   },
   "outputs": [],
   "source": "import nltk\nnltk.download(\"punkt\", quiet=True)\ntry:\n    nltk.download(\"punkt_tab\", quiet=True)\nexcept Exception:\n    pass\nprint(\"nltk ok\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "784CUqYSeoHr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843462361,
     "user_tz": 480,
     "elapsed": 11032,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "5f74d9a8-eb03-4a8a-a08d-d59b7928d5a1"
   },
   "outputs": [],
   "source": "import glob, re, json, shutil, math\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nfrom subprocess import run, PIPE\nfrom typing import List, Tuple\n\nfrom transformers import (\n    T5Tokenizer,\n    T5ForConditionalGeneration,\n)\n# decompx masker\nfrom rewrite.mask_orig import Masker as Masker_single\n\nimport transformers.modeling_utils as modeling_utils\n\ntry:\n    from transformers.modeling_utils import apply_chunking_to_forward\nexcept ImportError:\n    from transformers.pytorch_utils import apply_chunking_to_forward\n    modeling_utils.apply_chunking_to_forward = apply_chunking_to_forward\n\ntry:\n    from transformers.modeling_utils import find_pruneable_heads_and_indices\nexcept ImportError:\n    try:\n        from transformers.models.bert.modeling_bert import find_pruneable_heads_and_indices\n        modeling_utils.find_pruneable_heads_and_indices = find_pruneable_heads_and_indices\n    except ImportError:\n        def find_pruneable_heads_and_indices(*args, **kwargs):\n            raise NotImplementedError(\"find_pruneable_heads_and_indices not available\")\n        modeling_utils.find_pruneable_heads_and_indices = find_pruneable_heads_and_indices\n\ntry:\n    from transformers.modeling_utils import prune_linear_layer\nexcept ImportError:\n    try:\n        from transformers.models.bert.modeling_bert import prune_linear_layer\n        modeling_utils.prune_linear_layer = prune_linear_layer\n    except ImportError:\n        def prune_linear_layer(*args, **kwargs):\n            raise NotImplementedError(\"prune_linear_layer not available\")\n        modeling_utils.prune_linear_layer = prune_linear_layer\n\nprint(\"Imports done\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJ6WLuymeoHr"
   },
   "source": "## data config"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6TEERFXeoHr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843462395,
     "user_tz": 480,
     "elapsed": 31,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "68abf346-76cb-4031-b3df-acb849b8baa4"
   },
   "outputs": [],
   "source": "data_configs = {\n    \"paradetox\": {\n        \"data_path\": \"./datasets/paradetox/test_toxic_parallel.txt\",\n        \"format\": \"txt\",\n    },\n    \"microagressions_test\": {\n        \"data_path\": \"./datasets/microagressions/test.csv\",\n        \"format\": \"csv\",\n    },\n    \"sbf_test\": {\n        \"data_path\": \"./datasets/sbf/sbftst.csv\",\n        \"format\": \"csv\",\n    },\n    \"dynabench_test\": {\n        \"data_path\": \"./datasets/dynabench/db_test.csv\",\n        \"format\": \"csv\",\n    },\n    \"jigsaw_toxic\": {\n        \"data_path\": \"./datasets/jigsaw_full_30/test_10k_toxic.txt\",\n        \"format\": \"txt\",\n    },\n    \"appdia_original\": {\n        \"data_path\": \"./datasets/appdia/original-annotated-data/original-test.tsv\",\n        \"format\": \"tsv\",\n    },\n    \"appdia_discourse\": {\n        \"data_path\": \"./datasets/appdia/discourse-augmented-data/discourse-test.tsv\",\n        \"format\": \"tsv\",\n    },\n}\nprint(f\"{len(data_configs)} datasets\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fExrd6_JeoHs"
   },
   "source": "## helpers"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNg4xbyHeoHs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843462396,
     "user_tz": 480,
     "elapsed": 13,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "ff4e14d9-5423-4df0-c0fb-93fe7124e3cc"
   },
   "outputs": [],
   "source": "def _ensure_dir(p: str):\n    Path(p).mkdir(parents=True, exist_ok=True)\n\ndef load_test_data(data_type: str, num_examples: int = None) -> List[str]:\n    if data_type not in data_configs:\n        raise ValueError(f\"unknown: {data_type}\")\n\n    cfg = data_configs[data_type]\n    data_path = os.path.join(DATASET_BASE, cfg[\"data_path\"].lstrip(\"./\"))\n\n    texts = []\n\n    if cfg[\"format\"] == \"txt\":\n        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n            texts = [line.strip() for line in f if line.strip()]\n\n    elif cfg[\"format\"] == \"csv\":\n        df = pd.read_csv(data_path)\n        if \"text\" in df.columns:\n            texts = df[\"text\"].tolist()\n        elif \"toxic\" in df.columns:\n            texts = df[\"toxic\"].tolist()\n        else:\n            texts = df.iloc[:, 0].tolist()\n\n    elif cfg[\"format\"] == \"tsv\":\n        df = pd.read_csv(data_path, sep=\"\\t\")\n        if \"text\" in df.columns:\n            texts = df[\"text\"].tolist()\n        else:\n            texts = df.iloc[:, 0].tolist()\n\n    cleaned = []\n    for t in texts:\n        if pd.isna(t):\n            continue\n        s = str(t).strip()\n        if s:\n            cleaned.append(s)\n\n    if num_examples and num_examples > 0:\n        cleaned = cleaned[:num_examples]\n\n    return cleaned\n\ndef _safe_float(x):\n    try:\n        return float(x)\n    except Exception:\n        return float(\"nan\")\n\ndef _read_stats_file(path: str) -> dict:\n    out = {}\n    with open(path, \"r\") as f:\n        for line in f:\n            if \":\" not in line:\n                continue\n            k, v = line.strip().split(\": \", 1)\n            k = k.replace(\"(skipped)\", \"\").strip().lower()\n            out[k] = _safe_float(v)\n    return out\n\nprint(\"helpers ok\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1alT9KsbeoHs"
   },
   "source": "## t5 model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1drYIvieoHs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843509801,
     "user_tz": 480,
     "elapsed": 47409,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "f02a413d-7764-4692-c9ae-56389843d141"
   },
   "outputs": [],
   "source": "print(f\"loading t5 from {T5_CHECKPOINT}...\")\n\nt5_tokenizer = T5Tokenizer.from_pretrained(T5_CHECKPOINT)\nt5_model = T5ForConditionalGeneration.from_pretrained(T5_CHECKPOINT)\nt5_model.eval()\n\nDEVICE_T5 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nt5_model.to(DEVICE_T5)\n\nprint(f\"loaded on {DEVICE_T5}\")"
  },
  {
   "cell_type": "code",
   "source": "def t5_generate_candidates(\n    text: str,\n    model: T5ForConditionalGeneration,\n    tokenizer: T5Tokenizer,\n    num_candidates: int,\n    temperature: float = 1.0,\n    top_k: int = 50,\n    top_p: float = 0.95,\n    max_length: int = 128,\n    device: torch.device = DEVICE_T5,\n) -> List[str]:\n    \"\"\"gen candidates for single input\"\"\"\n    input_text = f\"detoxify: {text}\"\n    input_ids = tokenizer.encode(\n        input_text,\n        return_tensors=\"pt\",\n        max_length=max_length,\n        truncation=True,\n    ).to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids,\n            max_length=max_length,\n            num_return_sequences=num_candidates,\n            do_sample=True,\n            temperature=temperature,\n            top_k=top_k,\n            top_p=top_p,\n            no_repeat_ngram_size=2,\n        )\n\n    return [tokenizer.decode(out, skip_special_tokens=True) for out in outputs]\n\ndef t5_generate_candidates_batch(\n    texts: List[str],\n    model: T5ForConditionalGeneration,\n    tokenizer: T5Tokenizer,\n    num_candidates: int,\n    temperature: float = 1.0,\n    top_k: int = 50,\n    top_p: float = 0.95,\n    max_length: int = 128,\n    batch_size: int = 8,\n    device: torch.device = DEVICE_T5,\n) -> List[List[str]]:\n    \"\"\"batch gen\"\"\"\n    all_candidates: List[List[str]] = []\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"t5 gen\"):\n        batch_texts = texts[i:i + batch_size]\n        prompts = [f\"detoxify: {t}\" for t in batch_texts]\n\n        enc = tokenizer(\n            prompts,\n            return_tensors=\"pt\",\n            max_length=max_length,\n            truncation=True,\n            padding=True,\n        ).to(device)\n\n        with torch.no_grad():\n            outputs = model.generate(\n                **enc,\n                max_length=max_length,\n                num_return_sequences=num_candidates,\n                do_sample=True,\n                temperature=temperature,\n                top_k=top_k,\n                top_p=top_p,\n                no_repeat_ngram_size=2,\n            )\n\n        decoded = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n        B = len(batch_texts)\n        for b in range(B):\n            start = b * num_candidates\n            end = (b + 1) * num_candidates\n            all_candidates.append(decoded[start:end])\n\n    return all_candidates\n\n# test\ntest_text = \"This is a stupid idea\"\ntest_cands = t5_generate_candidates(test_text, t5_model, t5_tokenizer, num_candidates=3, device=DEVICE_T5)\nprint(f\"in: {test_text}\")\nfor i, c in enumerate(test_cands):\n    print(f\"  [{i}]: {c}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nax9JtmYUrEs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843516603,
     "user_tz": 480,
     "elapsed": 6805,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "2cb51db4-c4e0-483d-c927-f3d2963bc2b4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## decompx reranking",
   "metadata": {
    "id": "_B_75HaSU2dO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LtjFBnaeoHs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843516623,
     "user_tz": 480,
     "elapsed": 13,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "26b60f6d-9813-4e89-840d-2743e40e5d9f"
   },
   "outputs": [],
   "source": "def _decompx_mask_texts(\n    texts: List[str],\n    threshold: float = 0.20,\n    batch_size: int = 16,\n) -> List[str]:\n    \"\"\"run decompx masker\"\"\"\n    if not texts:\n        return []\n\n    masker = Masker_single()\n    masked_all = []\n    for i in tqdm(range(0, len(texts), batch_size),\n                  desc=\"decompx masking\", leave=False):\n        batch = texts[i:i + batch_size]\n        batch_out = masker.process_text(sentence=batch, threshold=threshold)\n        masked_all.extend(batch_out)\n    cleaned = [\n        m.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n        for m in masked_all\n    ]\n    masker.release_model()\n    return cleaned\n\ndef _decompx_toxicity_scores(\n    texts: List[str],\n    threshold: float = 0.20,\n    batch_size: int = 16,\n) -> np.ndarray:\n    \"\"\"score = mask_count / token_count\"\"\"\n    if not texts:\n        return np.zeros((0,), dtype=float)\n\n    masked = _decompx_mask_texts(texts, threshold=threshold, batch_size=batch_size)\n    scores = []\n    for m in masked:\n        num_masks = len(re.findall(r\"<mask>\", m))\n        tokens = m.split()\n        length = max(len(tokens), 1)\n        scores.append(num_masks / length)\n    return np.asarray(scores, dtype=float)\n\ndef rerank_candidates_decompx(\n    sources: List[str],\n    candidates: List[List[str]],\n    threshold: float = 0.20,\n    batch_size_mask: int = 16,\n):\n    \"\"\"pick lowest tox candidate per source\"\"\"\n    N = len(sources)\n    assert len(candidates) == N\n\n    if N == 0:\n        return np.array([], dtype=int), {}\n\n    C_list = [len(c) for c in candidates]\n    assert len(set(C_list)) == 1\n    C = C_list[0]\n    if C == 0:\n        raise ValueError(\"need >= 1 candidates\")\n\n    flat_cands = []\n    flat_src_idx = []\n    for i, cand_list in enumerate(candidates):\n        for cand in cand_list:\n            flat_cands.append(cand)\n            flat_src_idx.append(i)\n    flat_src_idx = np.array(flat_src_idx, dtype=int)\n\n    scores = _decompx_toxicity_scores(\n        flat_cands,\n        threshold=threshold,\n        batch_size=batch_size_mask,\n    )\n\n    scores2 = scores.reshape(N, C)\n    best_idx = np.argmin(scores2, axis=1)\n\n    details = {\"score\": scores2}\n    return best_idx, details\n\nprint(\"decompx reranking ready\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EBMYfvEeoHs"
   },
   "source": "## eval"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvlGUHVZeoHs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843516645,
     "user_tz": 480,
     "elapsed": 19,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "dae43ed0-db88-4a5b-decc-260c68b1ca86"
   },
   "outputs": [],
   "source": "def _eval_with_toxicity(base_path,\n                        overwrite_eval: bool = False,\n                        skip_ref: bool = False,\n                        tox_threshold: float = 0.5,\n                        tox_batch_size: int = 32):\n    import sys as _sys\n    for folder in os.listdir(base_path):\n        gen_dir = os.path.join(base_path, folder)\n        if not os.path.isdir(gen_dir):\n            continue\n        orig_path = os.path.join(gen_dir, \"orig.txt\")\n        gen_path  = os.path.join(gen_dir, \"gen.txt\")\n        out_stats = os.path.join(gen_dir, \"gen_stats.txt\")\n        if not (os.path.exists(orig_path) and os.path.exists(gen_path)):\n            continue\n        if os.path.exists(out_stats) and not overwrite_eval:\n            continue\n\n        env = os.environ.copy()\n        env[\"PYTHONPATH\"] = REPO + (\n            \":\" + env.get(\"PYTHONPATH\", \"\") if env.get(\"PYTHONPATH\") else \"\"\n        )\n        cmd = [\n            _sys.executable, \"-m\", \"evaluation.evaluate_all\",\n            \"--orig_path\", orig_path,\n            \"--gen_path\",  gen_path,\n            \"--tox_threshold\", str(tox_threshold),\n            \"--tox_batch_size\", str(tox_batch_size),\n        ]\n        if skip_ref:\n            cmd.append(\"--skip_ref\")\n        print(\"eval:\", \" \".join(cmd))\n        res = run(cmd, cwd=REPO, env=env, stdout=PIPE, stderr=PIPE, text=True)\n        if res.returncode != 0:\n            print(res.stdout)\n            print(res.stderr)\n            res.check_returncode()\n\ndef _aggregate_eval_csv(output_folder: str,\n                        data_type: str,\n                        base_out_dir: str):\n    rows = []\n\n    rerank_dir = \"T5_DecompX\"\n    base_path  = os.path.join(base_out_dir, data_type, rerank_dir)\n    if not os.path.isdir(base_path):\n        print(\"no eval dir:\", base_path)\n        return\n\n    for folder in os.listdir(base_path):\n        gen_dir    = os.path.join(base_path, folder)\n        stats_path = os.path.join(gen_dir, \"gen_stats.txt\")\n        if not os.path.exists(stats_path):\n            continue\n        s = _read_stats_file(stats_path)\n        rows.append({\n            \"threshold\":       0.20,\n            \"folder\":          folder,\n            \"bertscore\":       s.get(\"bertscore\", np.nan),\n            \"meaningbert\":     s.get(\"meaningbert\", np.nan),\n            \"bleu4\":           s.get(\"bleu4\", np.nan),\n            \"perplexity_gen\":  s.get(\"perplexity gen\", np.nan),\n            \"perplexity_orig\": s.get(\"perplexity orig\", np.nan),\n            \"toxicity_gen\":    s.get(\"toxicity gen\", np.nan),\n            \"toxicity_orig\":   s.get(\"toxicity orig\", np.nan),\n        })\n\n    if rows:\n        cols = [\n            \"threshold\", \"folder\",\n            \"bertscore\", \"meaningbert\", \"bleu4\",\n            \"perplexity_gen\", \"perplexity_orig\",\n            \"toxicity_gen\", \"toxicity_orig\",\n        ]\n        df = pd.DataFrame(rows)\n        df = df[cols]\n        out_csv = os.path.join(base_out_dir, data_type, f\"{data_type}.csv\")\n        _ensure_dir(os.path.dirname(out_csv))\n        df.to_csv(out_csv, index=False)\n        print(\"wrote:\", out_csv)\n    else:\n        print(\"no eval files\")\n\nprint(\"eval helpers ok\")"
  },
  {
   "cell_type": "code",
   "source": "def _build_run_folder_name_t5_decompx(\n    num_candidates: int,\n    max_length: int,\n    temperature: float,\n    top_k: int,\n    top_p: float,\n    decompx_threshold: float,\n) -> str:\n    return (\n        f\"t5_nc{num_candidates}_maxlen{max_length}_\"\n        f\"temp{temperature}_topk{top_k}_topp{top_p}_\"\n        f\"dxth{decompx_threshold}\"\n    )",
   "metadata": {
    "id": "OSX30Hxh0DoS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843516709,
     "user_tz": 480,
     "elapsed": 61,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvnm89jUeoHt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764843516712,
     "user_tz": 480,
     "elapsed": 21,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "d7ff3ee8-037f-4b0d-983d-3c8b65f28c1d"
   },
   "outputs": [],
   "source": "def detoxify(\n    data_type: str = \"paradetox\",\n    output_folder: str = \"T5_w_DecompX-Reranking_Pipeline\",\n    echo: bool = False,\n    num_examples: int = 1000,\n    batch_size: int = 8,\n    num_candidates: int = 10,\n    max_length: int = 128,\n    temperature: float = 1.0,\n    top_k: int = 50,\n    top_p: float = 0.95,\n    decompx_threshold: float = 0.20,\n    decompx_batch_size: int = 16,\n    overwrite_gen: bool = False,\n    run_eval: bool = True,\n    overwrite_eval: bool = False,\n    skip_ref_eval: bool = False,\n):\n    assert data_type in data_configs, f\"unknown: {data_type}\"\n\n    base_out_rel = os.path.join(\"data\", \"model_outputs\", output_folder)\n    base_out_abs = os.path.join(REPO, base_out_rel)\n    _ensure_dir(base_out_abs)\n\n    print(\"=\" * 60)\n    print(f\"[{data_type}] loading...\")\n    orig_texts = load_test_data(data_type, num_examples)\n    print(f\"  {len(orig_texts)} examples\")\n\n    if echo:\n        print(\"\\ninputs (first 3):\")\n        for i, s in enumerate(orig_texts[:3]):\n            print(f\"  [{i}]: {s}\")\n        print(f\"\\ndecompx thresh: {decompx_threshold}\")\n        print(f\"num_candidates: {num_candidates}\")\n\n    rerank_dir = \"T5_DecompX\"\n    cur_abs = os.path.join(base_out_abs, data_type, rerank_dir)\n    _ensure_dir(cur_abs)\n\n    run_folder = _build_run_folder_name_t5_decompx(\n        num_candidates=num_candidates,\n        max_length=max_length,\n        temperature=temperature,\n        top_k=top_k,\n        top_p=top_p,\n        decompx_threshold=decompx_threshold,\n    )\n    final_abs = os.path.join(cur_abs, run_folder)\n    _ensure_dir(final_abs)\n\n    orig_path  = os.path.join(final_abs, \"orig.txt\")\n    gen_path   = os.path.join(final_abs, \"gen.txt\")\n    stats_path = os.path.join(final_abs, \"gen_stats.txt\")\n\n    if overwrite_gen or not os.path.exists(gen_path):\n        print(\"  generating candidates...\")\n        all_candidates = t5_generate_candidates_batch(\n            texts=orig_texts,\n            model=t5_model,\n            tokenizer=t5_tokenizer,\n            num_candidates=num_candidates,\n            temperature=temperature,\n            top_k=top_k,\n            top_p=top_p,\n            max_length=max_length,\n            batch_size=batch_size,\n            device=DEVICE_T5,\n        )\n\n        if echo and all_candidates:\n            print(\"\\ncandidates for [0]:\")\n            for j, c in enumerate(all_candidates[0][:3]):\n                print(f\"    [{j}]: {c}\")\n\n        print(f\"  reranking (thresh={decompx_threshold:.2f})...\")\n        best_idx, details = rerank_candidates_decompx(\n            sources=orig_texts,\n            candidates=all_candidates,\n            threshold=decompx_threshold,\n            batch_size_mask=decompx_batch_size,\n        )\n        best_generations = [\n            all_candidates[i][best_idx[i]] for i in range(len(orig_texts))\n        ]\n\n        if echo:\n            print(\"\\nselected outputs (first 3):\")\n            for i, g in enumerate(best_generations[:3]):\n                print(f\"  [{i}]: {g}\")\n\n        with open(orig_path, \"w\") as f:\n            for t in orig_texts:\n                f.write(re.sub(r\"\\s+\", \" \", t).strip() + \"\\n\")\n        with open(gen_path, \"w\") as f:\n            for t in best_generations:\n                f.write(re.sub(r\"\\s+\", \" \", t).strip() + \"\\n\")\n\n        print(\"  saved:\", final_abs)\n    else:\n        print(\"  reusing:\", final_abs)\n        with open(orig_path, \"r\") as f:\n            orig_texts = [l.strip() for l in f]\n        with open(gen_path, \"r\") as f:\n            best_generations = [l.strip() for l in f]\n        print(f\"  loaded {len(best_generations)} gen\")\n\n    metrics = None\n    if run_eval:\n        base_path = os.path.join(base_out_abs, data_type, rerank_dir)\n        _eval_with_toxicity(\n            base_path,\n            overwrite_eval=overwrite_eval,\n            skip_ref=skip_ref_eval,\n            tox_threshold=0.5,\n            tox_batch_size=32,\n        )\n        _aggregate_eval_csv(\n            output_folder,\n            data_type,\n            os.path.join(REPO, \"data\", \"model_outputs\", output_folder),\n        )\n\n        if os.path.exists(stats_path):\n            metrics = _read_stats_file(stats_path)\n            if echo:\n                print(\"\\nmetrics:\")\n                for k, v in metrics.items():\n                    if isinstance(v, float) and math.isnan(v):\n                        continue\n                    print(f\"  {k}: {v:.4f}\")\n        else:\n            print(\"  no stats file\")\n\n    print(\"=\" * 60)\n    return metrics\n\nprint(\"detoxify() ready\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYhL4PZoeoHt",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d9fa30fb011c40f0a5ff0ed73563cf8e",
      "68e7ed1395a2451da4bab619de34e553",
      "5320369743274bb3923ff70e7b6e4851",
      "f71fb6720b724e7db15968ae2b1b289e",
      "97a943e8f0d448f1b00a8dff35d95c2f",
      "181dded5a16d48c688e0302049ab7315",
      "9ae114b12c354618b84cec044810276b",
      "fbe5387e200a4b68a03557f215aaf9fd",
      "a47ceb8cb5c54753bbbc063e2a0c2edc",
      "7a9f5ee14726400aa28be267b2af989a",
      "6f2d9b4364284d85ae8e138e8001d000",
      "3a6bef4c7e7f4036b887e8a1cf4a1daa",
      "0ccce364a1564d0cbc5b693848a9ed43",
      "3b6fd9b7cd2649e48c63e568e32ba5ba",
      "9e7a558bc7784fe18157d95acde90162",
      "d4fcfb7905534e85a232dae9d6371bd4",
      "f0d20aeed9bc4213a8851a96792c17bd",
      "ce16ba3c4baf46228ca5841c146b7b66",
      "a14045c3c03f4858bf2231dd14fc743a",
      "6e9a73b3a6f24315bc3aed9e4cbc6353",
      "6e8bbd04a5cf407ea246f61a62fb4609",
      "3bf27dfd1b3b4b1da19aa3d632b38536"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764844526287,
     "user_tz": 480,
     "elapsed": 1009580,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "b4ec0927-f396-4f79-e708-785ce138f72b"
   },
   "outputs": [],
   "source": "metrics_paradetox = detoxify(\n    data_type=\"paradetox\",\n    output_folder=\"T5_w_DecompX-Reranking_Pipeline - KB\",\n    echo=True,\n    num_examples=1000,\n    batch_size=8,\n    num_candidates=10,\n    max_length=128,\n    temperature=1.0,\n    top_k=50,\n    top_p=0.95,\n    decompx_threshold=0.20,\n    decompx_batch_size=16,\n    overwrite_gen=True,\n    run_eval=True,\n    overwrite_eval=True,\n    skip_ref_eval=False,\n)\n\nprint(\"\\nparadetox results:\")\nif metrics_paradetox:\n    for k, v in metrics_paradetox.items():\n        if isinstance(v, float) and math.isnan(v):\n            continue\n        print(f\"  {k}: {v:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wSlQBk1AeoHt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764844526307,
     "user_tz": 480,
     "elapsed": 12,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "outputs": [],
   "source": [
    "# #@title Run on multiple datasets\n",
    "\n",
    "# datasets_to_eval = [\"paradetox\", \"microagressions_test\", \"sbf_test\", \"dynabench_test\"]\n",
    "# num_examples = 200\n",
    "# output_folder = \"T5_w_DecompX-Reranking_Pipeline\"\n",
    "\n",
    "# all_results = {}\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"T5-PARADETOX + DECOMPX RERANKING PIPELINE (evaluate_all)\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# for dataset_name in datasets_to_eval:\n",
    "#     try:\n",
    "#         results = detoxify(\n",
    "#             data_type=dataset_name,\n",
    "#             output_folder=output_folder,\n",
    "#             echo=False,\n",
    "#             num_examples=num_examples,\n",
    "#             batch_size=8,\n",
    "#             num_candidates=10,\n",
    "#             max_length=128,\n",
    "#             temperature=1.0,\n",
    "#             top_k=50,\n",
    "#             top_p=0.95,\n",
    "#             decompx_threshold=0.20,\n",
    "#             decompx_batch_size=16,\n",
    "#             overwrite_gen=False,\n",
    "#             run_eval=True,\n",
    "#             overwrite_eval=False,\n",
    "#             skip_ref_eval=False,\n",
    "#         )\n",
    "#         if results:\n",
    "#             all_results[dataset_name] = results\n",
    "#             print(f\"  {dataset_name}: done\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  Error on {dataset_name}: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         continue\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# # Optional short summary of this batch of runs\n",
    "# if all_results:\n",
    "#     rows = []\n",
    "#     for dataset_name, results in all_results.items():\n",
    "#         row = {\"dataset\": dataset_name}\n",
    "#         row.update(results)\n",
    "#         rows.append(row)\n",
    "\n",
    "#     df = pd.DataFrame(rows)\n",
    "\n",
    "#     # Map keys with spaces to snake_case for convenience\n",
    "#     rename_map = {\n",
    "#         \"perplexity gen\": \"perplexity_gen\",\n",
    "#         \"perplexity orig\": \"perplexity_orig\",\n",
    "#         \"toxicity gen\": \"toxicity_gen\",\n",
    "#         \"toxicity orig\": \"toxicity_orig\",\n",
    "#     }\n",
    "#     df = df.rename(columns=rename_map)\n",
    "\n",
    "#     col_order = [\n",
    "#         \"dataset\",\n",
    "#         \"bertscore\",\n",
    "#         \"meaningbert\",\n",
    "#         \"bleu4\",\n",
    "#         \"perplexity_gen\",\n",
    "#         \"perplexity_orig\",\n",
    "#         \"toxicity_gen\",\n",
    "#         \"toxicity_orig\",\n",
    "#     ]\n",
    "#     df = df[[c for c in col_order if c in df.columns]]\n",
    "\n",
    "#     summary_csv = os.path.join(\n",
    "#         XDETOX_DIR,\n",
    "#         \"data\",\n",
    "#         \"model_outputs\",\n",
    "#         output_folder,\n",
    "#         \"t5_decompx_summary_latest_run.csv\",\n",
    "#     )\n",
    "#     _ensure_dir(os.path.dirname(summary_csv))\n",
    "#     df.to_csv(summary_csv, index=False)\n",
    "#     print(f\"Saved summary of this run to {summary_csv}\\n\")\n",
    "#     print(df.to_string(index=False))\n",
    "# else:\n",
    "#     print(\"No per-run metrics collected (per-dataset CSVs still written under data/model_outputs).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "JfCJf7L7l_0K",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764844526314,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "execution_count": 16,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d9fa30fb011c40f0a5ff0ed73563cf8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68e7ed1395a2451da4bab619de34e553",
       "IPY_MODEL_5320369743274bb3923ff70e7b6e4851",
       "IPY_MODEL_f71fb6720b724e7db15968ae2b1b289e"
      ],
      "layout": "IPY_MODEL_97a943e8f0d448f1b00a8dff35d95c2f"
     }
    },
    "68e7ed1395a2451da4bab619de34e553": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_181dded5a16d48c688e0302049ab7315",
      "placeholder": "​",
      "style": "IPY_MODEL_9ae114b12c354618b84cec044810276b",
      "value": "T5 Generation: 100%"
     }
    },
    "5320369743274bb3923ff70e7b6e4851": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbe5387e200a4b68a03557f215aaf9fd",
      "max": 84,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a47ceb8cb5c54753bbbc063e2a0c2edc",
      "value": 84
     }
    },
    "f71fb6720b724e7db15968ae2b1b289e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a9f5ee14726400aa28be267b2af989a",
      "placeholder": "​",
      "style": "IPY_MODEL_6f2d9b4364284d85ae8e138e8001d000",
      "value": " 84/84 [01:33&lt;00:00,  1.06it/s]"
     }
    },
    "97a943e8f0d448f1b00a8dff35d95c2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "181dded5a16d48c688e0302049ab7315": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ae114b12c354618b84cec044810276b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbe5387e200a4b68a03557f215aaf9fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47ceb8cb5c54753bbbc063e2a0c2edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a9f5ee14726400aa28be267b2af989a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f2d9b4364284d85ae8e138e8001d000": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a6bef4c7e7f4036b887e8a1cf4a1daa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ccce364a1564d0cbc5b693848a9ed43",
       "IPY_MODEL_3b6fd9b7cd2649e48c63e568e32ba5ba",
       "IPY_MODEL_9e7a558bc7784fe18157d95acde90162"
      ],
      "layout": "IPY_MODEL_d4fcfb7905534e85a232dae9d6371bd4"
     }
    },
    "0ccce364a1564d0cbc5b693848a9ed43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0d20aeed9bc4213a8851a96792c17bd",
      "placeholder": "​",
      "style": "IPY_MODEL_ce16ba3c4baf46228ca5841c146b7b66",
      "value": "DecompX masking for reranking: 100%"
     }
    },
    "3b6fd9b7cd2649e48c63e568e32ba5ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a14045c3c03f4858bf2231dd14fc743a",
      "max": 420,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e9a73b3a6f24315bc3aed9e4cbc6353",
      "value": 420
     }
    },
    "9e7a558bc7784fe18157d95acde90162": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e8bbd04a5cf407ea246f61a62fb4609",
      "placeholder": "​",
      "style": "IPY_MODEL_3bf27dfd1b3b4b1da19aa3d632b38536",
      "value": " 419/420 [02:40&lt;00:00,  4.31it/s]"
     }
    },
    "d4fcfb7905534e85a232dae9d6371bd4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "f0d20aeed9bc4213a8851a96792c17bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce16ba3c4baf46228ca5841c146b7b66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a14045c3c03f4858bf2231dd14fc743a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e9a73b3a6f24315bc3aed9e4cbc6353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e8bbd04a5cf407ea246f61a62fb4609": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bf27dfd1b3b4b1da19aa3d632b38536": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}