{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d4549b",
   "metadata": {
    "id": "82d4549b"
   },
   "source": "# xdetox pipeline w/ global reranking\n\nruns the full pipeline with:\n\n1. **decompx masking** (token-level toxicity attribution on roberta).\n2. **marco-style generation** (base / expert / anti-expert bart mixture).\n3. **global reranking** of multiple candidates using:\n   - **toxicity** (xlm-r large classifier).\n   - **semantic similarity** (labse).\n   - **fluency** (gpt-2 perplexity).\n\ngoal: pick best detoxified candidate that is:\n- as non-toxic as possible\n- semantically close to original\n- fluent\n\n---\n\n## scoring\n\nFor each candidate $c$ we compute:\n\n- $T(c)$: toxicity in $[0,1]$ from `textdetox/xlmr-large-toxicity-classifier-v2`.\n- $S(c)$: semantic similarity in $[0,1]$, from labse cosine similarity.\n- $F(c)$: fluency in $[0,1]$, from gpt-2 perplexity mapped to a score\n  (low perplexity → high fluency).\n\nconvert toxicity to safety score:\n\n$$T'(c) = 1 - T(c)$$\n\nglobal score:\n\n$$\\text{Score}(c) = w_T \\cdot T'(c) + w_S \\cdot S(c) + w_F \\cdot F(c)$$\n\nweights:\n\n- `weights = (w_T, w_S, w_F)`  \n  - `w_T`: importance of **safety** (low toxicity).  \n  - `w_S`: importance of **semantic similarity**.  \n  - `w_F`: importance of **fluency**.\n\nfor each input:\n\n1. generate `num_candidates` candidates.\n2. score each candidate.\n3. select highest-scoring candidate.\n\n---\n\n## masking and generation\n\nfor each dataset:\n\n1. **subset selection**  \n   - can run on full dataset or only first `num_examples` rows.\n   - subset file written under `datasets/_subsets/{data_type}/`.\n\n2. **decompx masking**  \n   - use `rewrite.mask_orig.Masker` (roberta + decompx) to detect toxic tokens.\n   - toxic tokens replaced by `<mask>`.\n   - masked inputs saved as `masked_inputs.txt`.\n\n3. **marco generation (bart ensemble)**  \n   - use `rewrite.generation.Infiller` with:\n     - base model (bart),\n     - expert model (non-toxic),\n     - anti-expert model (toxic).\n   - generation controlled by:\n     - `alpha_a`, `alpha_e`, `alpha_b` (expert/anti-expert weights),\n     - `temperature`, `top_k_gen`, `top_p`, `filter_p`, `rep_penalty`, `max_length`,\n     - `sample` (use sampling or greedy decoding).\n   - for each input, sample `num_candidates` different candidates.\n\n4. **global reranking**  \n   - all candidates scored by toxicity + similarity + fluency.\n   - best candidate written to `gen.txt` (one line per input).\n   - original texts written to `orig.txt`.\n\n---\n\n## evaluation\n\nif `run_eval=True`, pipeline calls `evaluation.evaluate_all` to compute:\n\n- bertscore (f1)\n- meaningbert\n- bleu-4\n- toxicity (orig / gen)\n- perplexity (orig / gen)\n\nwrites `gen_stats.txt` for each `(threshold, run)` folder.  \nalso creates summary csv per dataset:\n\n- `data/model_outputs/{output_folder}/{data_type}/{data_type}.csv`\n\nwith metrics aggregated across thresholds.\n\n---\n\n## how to use\n\nsignature:\n\n```python\ndef detoxify(\n    data_type: str = \"paradetox\",\n    output_folder: str = \"colab_run_global\",\n    thresholds = (0.15, 0.20, 0.25),\n    batch_size: int = 10,\n    sample: bool = True,\n    top_k_gen: int = 50,\n    top_p: float = 0.95,\n    filter_p: float = 1.0,\n    max_length: int = 128,\n    alpha_a: float = None,\n    alpha_e: float = None,\n    alpha_b: float = 1.0,\n    temperature: float = None,\n    rep_penalty: float = None,\n    num_examples: int = 100,\n    overwrite_gen: bool = False,\n    run_eval: bool = False,\n    overwrite_eval: bool = False,\n    skip_ref_eval: bool = False,\n    weights = (0.5, 0.3, 0.2),\n    num_candidates: int = 3,\n)\n```\n\n### key arguments\n\n* **core i/o**\n\n  * `data_type`: dataset key from `data_configs`\n    (e.g. `\"paradetox\"`, `\"dynabench_val\"`, `\"jigsaw_toxic\"`, etc.).\n  * `output_folder`: folder under `data/model_outputs/` where results stored.\n\n* **masking / thresholds**\n\n  * `thresholds`: tuple of decompx thresholds to try\n    (e.g. `(0.15, 0.20, 0.25)`). each value creates a `DecompX{thresh}` subfolder.\n  * `num_examples`: if set, only first `num_examples` used (for quick runs).\n    use `None` to process full dataset.\n\n* **generation (marco / bart)**\n\n  * `sample`: `True` → stochastic sampling; `False` → greedy decoding.\n  * `top_k_gen`: top-k for sampling on ensembled logits.\n  * `top_p`: nucleus sampling on ensembled logits.\n  * `filter_p`: nucleus filter on **base** logits (advanced; often `1.0`).\n  * `max_length`: maximum generation length (tokens).\n  * `alpha_a`, `alpha_e`, `alpha_b`: anti-expert / expert / base weights.\n    if `None`, defaults taken from `data_configs[data_type]`.\n  * `temperature`: sampling temperature; if `None`, use dataset default.\n  * `rep_penalty`: repetition penalty; if `None`, use dataset default.\n  * `batch_size`: generation batch size (trade-off of speed vs memory).\n\n* **global reranking**\n\n  * `weights=(w_T, w_S, w_F)`: weights for safety, similarity, fluency.\n  * `num_candidates`: how many candidates to generate per input\n    (larger → better reranking, but slower).\n\n* **evaluation**\n\n  * `run_eval`: if `True`, run evaluation and write `gen_stats.txt`.\n  * `overwrite_gen`: if `True`, regenerate even if `gen.txt` exists.\n  * `overwrite_eval`: if `True`, recompute evaluation even if `gen_stats.txt` exists.\n  * `skip_ref_eval`: if `True`, skip perplexity on references.\n\n* **echo**\n  * `echo`: if `True`, print example inputs, masked inputs, generated outputs, and per-threshold evaluation metrics.\n---\n\n## example calls\n\nquick sanity check on small subset:\n\n```python\ndetoxify(\n    data_type=\"paradetox\",\n    output_folder=\"colab_run_global_demo\",\n    thresholds=(0.20,),\n    batch_size=8,\n    sample=True,\n    top_k_gen=50,\n    top_p=0.95,\n    max_length=96,\n    num_examples=50,\n    run_eval=True,\n    overwrite_gen=False,\n    overwrite_eval=True,\n    skip_ref_eval=False,\n    weights=(0.5, 0.3, 0.2),\n    num_candidates=20,\n)\n```\n\nfull-dataset run:\n\n```python\ndetoxify(\n    data_type=\"paradetox\",\n    output_folder=\"paradetox_full_global\",\n    thresholds=(0.15, 0.20, 0.25),\n    batch_size=8,\n    sample=True,\n    top_k_gen=50,\n    top_p=0.95,\n    max_length=96,\n    num_examples=None,\n    run_eval=True,\n    overwrite_gen=False,\n    overwrite_eval=False,\n    weights=(0.5, 0.3, 0.2),\n    num_candidates=10,\n)\n```\n\nafter running `detoxify`, check:\n\n* `data/model_outputs/{output_folder}/{data_type}/DecompX*/.../orig.txt`\n* `data/model_outputs/{output_folder}/{data_type}/DecompX*/.../gen.txt`\n* `data/model_outputs/{output_folder}/{data_type}/DecompX*/.../gen_stats.txt`\n* `data/model_outputs/{output_folder}/{data_type}/{data_type}.csv` (summary)."
  },
  {
   "cell_type": "code",
   "source": "from google.colab import drive; drive.mount('/content/drive')\n\nimport os, glob, re, sys, json, shutil, math\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nfrom subprocess import run, PIPE\nimport torch\nimport nltk\nfrom typing import List\n\ncandidate = \"/content/drive/MyDrive/w266 - Project/XDetox\"\nprint(\"trying mydrive:\", candidate, \"->\", os.path.isdir(candidate))\n\nXDETOX_DIR = candidate\nprint(\"using xdetox_dir:\", XDETOX_DIR)\nassert os.path.isdir(XDETOX_DIR), f\"XDETOX_DIR does not exist: {XDETOX_DIR}\"",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfBoQTrjtynY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461853511,
     "user_tz": 480,
     "elapsed": 921,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "68e71a64-ee45-4d46-f36e-a549cb09d189"
   },
   "id": "kfBoQTrjtynY",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "HF_CACHE = os.path.join(XDETOX_DIR, \"cache\")\nos.makedirs(HF_CACHE, exist_ok=True)\nos.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n\nif XDETOX_DIR not in sys.path:\n    sys.path.append(XDETOX_DIR)\n\nprint(\"xdetox_dir:\", XDETOX_DIR)\nprint(\"cache:\", HF_CACHE)\nprint(\"cuda available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"gpu:\", torch.cuda.get_device_name(0))",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ITPlTNBtzQx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461853519,
     "user_tz": 480,
     "elapsed": 10,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "d52a561c-4c52-4b3c-a209-5e5c7020bfd1"
   },
   "id": "7ITPlTNBtzQx",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for d in [\"rewrite\", \"evaluation\", \"datasets\"]:\n    assert os.path.isdir(os.path.join(XDETOX_DIR, d)), f\"Missing folder: {d}\"\nprint(\"repo folders ok\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEy2TGYetzIb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461853530,
     "user_tz": 480,
     "elapsed": 8,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "d247eaf1-36a5-4825-fcea-6ec4c898a767"
   },
   "id": "MEy2TGYetzIb",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip -q install --upgrade pip setuptools wheel\n!pip -q install \"transformers==4.41.2\" \"tokenizers==0.19.1\" \\\n                \"datasets==2.19.0\" \"evaluate==0.4.1\" \\\n                \"sacrebleu==2.4.1\" sacremoses ftfy nltk matplotlib pandas jedi\n\n!pip -q install bert-score",
   "metadata": {
    "id": "GeTzwxVDtzNn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859283,
     "user_tz": 480,
     "elapsed": 5752,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "GeTzwxVDtzNn",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from transformers import (\n    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n    GPT2LMHeadModel, GPT2TokenizerFast,\n)",
   "metadata": {
    "id": "tfnuR2YVCmW9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859312,
     "user_tz": 480,
     "elapsed": 12,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "tfnuR2YVCmW9",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from rewrite.mask_orig import Masker as Masker_single\nfrom rewrite.generation import Infiller\nfrom rewrite import rewrite_example as rx\nimport argparse as _argparse",
   "metadata": {
    "id": "ccJxAWrjA8Qc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859317,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "ccJxAWrjA8Qc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "nltk.download(\"punkt\", quiet=True)\ntry:\n    nltk.download(\"punkt_tab\", quiet=True)\nexcept Exception:\n    pass\nprint(\"ready\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0Up7SKstzK9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859348,
     "user_tz": 480,
     "elapsed": 29,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "ec4d2c15-05e1-4165-bb75-f7fdd73722e9"
   },
   "id": "y0Up7SKstzK9",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "data_configs = {\n    \"microagressions_val\": {\n        \"data_path\": \"./datasets/microagressions/val.csv\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.25,\n        \"temperature\": 2.5,\n    },\n    \"microagressions_test\": {\n        \"data_path\": \"./datasets/microagressions/test.csv\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.25,\n        \"temperature\": 2.5,\n    },\n    \"sbf_val\": {\n        \"data_path\": \"./datasets/sbf/sbfdev.csv\",\n        \"rep_penalty\": 1.5,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 5.0,\n        \"temperature\": 2.9,\n    },\n    \"sbf_test\": {\n        \"data_path\": \"./datasets/sbf/sbftst.csv\",\n        \"rep_penalty\": 1.5,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 5.0,\n        \"temperature\": 2.9,\n    },\n    \"dynabench_val\": {\n        \"data_path\": \"./datasets/dynabench/db_dev.csv\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.75,\n        \"temperature\": 2.5,\n    },\n    \"dynabench_test\": {\n        \"data_path\": \"./datasets/dynabench/db_test.csv\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.75,\n        \"temperature\": 2.5,\n    },\n    \"jigsaw_toxic\": {\n        \"data_path\": \"./datasets/jigsaw_full_30/test_10k_toxic.txt\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.75,\n        \"temperature\": 2.5,\n    },\n    \"paradetox\": {\n        \"data_path\": \"./datasets/paradetox/test_toxic_parallel.txt\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.75,\n        \"temperature\": 2.5,\n    },\n    \"appdia_original\": {\n        \"data_path\": \"./datasets/appdia/original-annotated-data/original-test.tsv\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.75,\n        \"temperature\": 2.5,\n    },\n    \"appdia_discourse\": {\n        \"data_path\": \"./datasets/appdia/discourse-augmented-data/discourse-test.tsv\",\n        \"rep_penalty\": 1.0,\n        \"alpha_a\": 1.5,\n        \"alpha_e\": 4.75,\n        \"temperature\": 2.5,\n    }\n}\nprint(\"datasets:\", \", \".join(data_configs.keys()))\n\nREPO = XDETOX_DIR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nBku39IuAgb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859356,
     "user_tz": 480,
     "elapsed": 6,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "09e348d9-558b-4c38-91ae-e4569530ae15"
   },
   "id": "7nBku39IuAgb",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def _abs_repo_path(rel: str) -> str:\n    return os.path.join(REPO, rel.lstrip(\"./\"))\n\ndef _ensure_dir(p: str):\n    Path(p).mkdir(parents=True, exist_ok=True)\n\ndef _subset_for_data_type(data_type, data_path, n, out_dir):\n    if n is None or n <= 0:\n        return data_path\n\n    src = _abs_repo_path(data_path)\n    _ensure_dir(out_dir)\n\n    if \"microagressions\" in data_path:\n        df = pd.read_csv(src)\n        sub = df.head(n)\n        out = os.path.join(out_dir, os.path.basename(src))\n        sub.to_csv(out, index=False)\n        return out\n\n    if \"sbf\" in data_path:\n        df = pd.read_csv(src)\n        sub = df.head(n)\n        out = os.path.join(out_dir, os.path.basename(src))\n        sub.to_csv(out, index=False)\n        return out\n\n    if \"dynabench\" in data_path:\n        df = pd.read_csv(src)\n        sub = df.head(n)\n        out = os.path.join(out_dir, os.path.basename(src))\n        sub.to_csv(out, index=False)\n        return out\n\n    if any(k in data_path for k in [\"paradetox\", \"jigsaw\"]):\n        if data_path.endswith(\".txt\"):\n            with open(src, \"r\") as f:\n                lines = [s.rstrip(\"\\n\") for s in f.readlines()]\n            out = os.path.join(out_dir, os.path.basename(src))\n            with open(out, \"w\") as g:\n                for s in lines[:n]:\n                    g.write(s + \"\\n\")\n            return out\n        elif data_path.endswith(\".csv\"):\n            df = pd.read_csv(src).head(n)\n            out = os.path.join(out_dir, os.path.basename(src))\n            df.to_csv(out, index=False)\n            return out\n\n    if \"appdia\" in data_path:\n        df = pd.read_csv(src, sep=\"\\t\").head(n)\n        out = os.path.join(out_dir, os.path.basename(src))\n        df.to_csv(out, sep=\"\\t\", index=False)\n        return out\n\n    out = os.path.join(out_dir, os.path.basename(src))\n    shutil.copy(src, out)\n    return out",
   "metadata": {
    "id": "ToytrY0SuAjr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859391,
     "user_tz": 480,
     "elapsed": 25,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "ToytrY0SuAjr",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "DEVICE_SCORE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"scoring models will use: {DEVICE_SCORE}\")\n\n_TOX_MODEL_NAME = \"textdetox/xlmr-large-toxicity-classifier-v2\"\n_TOX_TOKENIZER = None\n_TOX_MODEL = None\n\ndef _lazy_load_tox():\n    global _TOX_TOKENIZER, _TOX_MODEL\n    if _TOX_TOKENIZER is None or _TOX_MODEL is None:\n        _TOX_TOKENIZER = AutoTokenizer.from_pretrained(_TOX_MODEL_NAME)\n        _TOX_MODEL = AutoModelForSequenceClassification.from_pretrained(\n            _TOX_MODEL_NAME\n        ).to(DEVICE_SCORE)\n        _TOX_MODEL.eval()\n\n@torch.no_grad()\ndef get_toxicity_scores(texts, batch_size=32):\n    _lazy_load_tox()\n    scores = []\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"toxicity\", leave=False):\n        batch = texts[i:i+batch_size]\n        enc = _TOX_TOKENIZER(\n            batch, return_tensors=\"pt\",\n            truncation=True, max_length=512, padding=True\n        ).to(DEVICE_SCORE)\n        logits = _TOX_MODEL(**enc).logits\n        probs = torch.softmax(logits, dim=-1)\n        scores.extend(probs[:, 1].detach().cpu().tolist())\n    return scores\n\n_LABSE_NAME = \"sentence-transformers/LaBSE\"\n_LABSE_TOKENIZER = None\n_LABSE_MODEL = None\n\ndef _lazy_load_labse():\n    global _LABSE_TOKENIZER, _LABSE_MODEL\n    if _LABSE_TOKENIZER is None or _LABSE_MODEL is None:\n        _LABSE_TOKENIZER = AutoTokenizer.from_pretrained(_LABSE_NAME)\n        _LABSE_MODEL = AutoModel.from_pretrained(_LABSE_NAME).to(DEVICE_SCORE)\n        _LABSE_MODEL.eval()\n\n@torch.no_grad()\ndef get_labse_embeddings(texts, batch_size=32):\n    _lazy_load_labse()\n    embs = []\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"labse embeddings\", leave=False):\n        batch = texts[i:i+batch_size]\n        enc = _LABSE_TOKENIZER(\n            batch, return_tensors=\"pt\",\n            truncation=True, max_length=256, padding=True\n        ).to(DEVICE_SCORE)\n        outputs = _LABSE_MODEL(**enc)\n        hidden = outputs.last_hidden_state\n        mask = enc[\"attention_mask\"].unsqueeze(-1)\n        masked = hidden * mask\n        summed = masked.sum(dim=1)\n        counts = mask.sum(dim=1).clamp(min=1e-6)\n        sent_emb = (summed / counts).cpu().numpy()\n        embs.append(sent_emb)\n    if not embs:\n        return np.zeros((0, 768), dtype=np.float32)\n    return np.vstack(embs)\n\n_GPT2_NAME = \"gpt2\"\n_GPT2_TOKENIZER = None\n_GPT2_MODEL = None\n\ndef _lazy_load_gpt2():\n    global _GPT2_TOKENIZER, _GPT2_MODEL\n    if _GPT2_TOKENIZER is None or _GPT2_MODEL is None:\n        _GPT2_TOKENIZER = GPT2TokenizerFast.from_pretrained(_GPT2_NAME)\n        _GPT2_MODEL = GPT2LMHeadModel.from_pretrained(_GPT2_NAME).to(DEVICE_SCORE)\n        _GPT2_MODEL.eval()\n\n@torch.no_grad()\ndef get_gpt2_perplexities(texts):\n    import math as _math\n    _lazy_load_gpt2()\n    ppls = []\n    for s in tqdm(texts, desc=\"gpt-2 ppl\", leave=False):\n        enc = _GPT2_TOKENIZER(s, return_tensors=\"pt\").to(DEVICE_SCORE)\n        out = _GPT2_MODEL(enc[\"input_ids\"], labels=enc[\"input_ids\"])\n        ppl = _math.exp(out.loss.item())\n        if ppl > 1e4:\n            ppl = 1e4\n        ppls.append(float(ppl))\n    return ppls\n\ndef perplexity_to_fluency(ppls, p_min=5.0, p_max=300.0):\n    import math as _math\n    ppls = np.asarray(ppls, dtype=float)\n    p = np.clip(ppls, p_min, p_max)\n    log_p = np.log(p)\n    log_min = _math.log(p_min)\n    log_max = _math.log(p_max)\n    F = (log_max - log_p) / (log_max - log_min + 1e-8)\n    F = np.clip(F, 0.0, 1.0)\n    return F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MxQChqOuAnT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859410,
     "user_tz": 480,
     "elapsed": 17,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "049ee8b0-a07d-4136-e210-992ca9b3ede1"
   },
   "id": "-MxQChqOuAnT",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def rerank_candidates_global(\n    sources,\n    candidates,\n    weights=(0.5, 0.3, 0.2),\n    ppl_min=5.0,\n    ppl_max=300.0,\n):\n    w_T, w_S, w_F = weights\n    N = len(sources)\n    assert len(candidates) == N, \"candidates length mismatch\"\n\n    if N == 0:\n        return np.array([], dtype=int), {}\n\n    C_list = [len(c) for c in candidates]\n    assert len(set(C_list)) == 1, \"All inputs must have same num_candidates\"\n    C = C_list[0]\n    if C == 0:\n        raise ValueError(\"num_candidates must be >= 1\")\n\n    flat_cands = []\n    flat_src_idx = []\n    for i, cand_list in enumerate(candidates):\n        for cand in cand_list:\n            flat_cands.append(cand)\n            flat_src_idx.append(i)\n    flat_src_idx = np.array(flat_src_idx, dtype=int)\n\n    tox = np.array(get_toxicity_scores(flat_cands), dtype=float)\n\n    src_embs = get_labse_embeddings(sources)\n    cand_embs = get_labse_embeddings(flat_cands)\n    src_embs = src_embs / np.clip(np.linalg.norm(src_embs, axis=1, keepdims=True), 1e-8, None)\n    cand_embs = cand_embs / np.clip(np.linalg.norm(cand_embs, axis=1, keepdims=True), 1e-8, None)\n    sims = np.sum(cand_embs * src_embs[flat_src_idx], axis=1)\n    sims = (sims + 1.0) / 2.0\n\n    ppls = np.array(get_gpt2_perplexities(flat_cands), dtype=float)\n    flus = perplexity_to_fluency(ppls, p_min=ppl_min, p_max=ppl_max)\n\n    safety = 1.0 - tox\n\n    scores = w_T * safety + w_S * sims + w_F * flus\n\n    tox2     = tox.reshape(N, C)\n    safety2  = safety.reshape(N, C)\n    sims2    = sims.reshape(N, C)\n    flus2    = flus.reshape(N, C)\n    scores2  = scores.reshape(N, C)\n\n    best_idx = scores2.argmax(axis=1)\n    details = {\n        \"tox\": tox2,\n        \"safety\": safety2,\n        \"sim\": sims2,\n        \"flu\": flus2,\n        \"score\": scores2,\n    }\n    return best_idx, details",
   "metadata": {
    "id": "dom7rBbguA2u",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859424,
     "user_tz": 480,
     "elapsed": 12,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "dom7rBbguA2u",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def _parse_run_folder_name(folder_name):\n    pattern = r\"aa(\\d+\\.\\d+)_ae(\\d+\\.\\d+)_ab(\\d+\\.\\d+)_base(.*?)_anti(.*?)_expert(.*?)_temp(\\d+\\.\\d+)_sample(.*?)_topk(\\d+)_reppenalty(\\d+\\.\\d+)_filterp(\\d+\\.\\d+)_maxlength(\\d+)_topp(\\d+\\.\\d+)\"\n    m = re.match(pattern, folder_name)\n    return bool(m)\n\ndef _eval_with_toxicity(base_path, overwrite_eval=False, skip_ref=False, tox_threshold=0.5, tox_batch_size=32):\n    import sys as _sys, os as _os\n    for folder in os.listdir(base_path):\n        gen_dir = os.path.join(base_path, folder)\n        if not os.path.isdir(gen_dir) or not _parse_run_folder_name(folder):\n            continue\n        orig_path = os.path.join(gen_dir, \"orig.txt\")\n        gen_path  = os.path.join(gen_dir, \"gen.txt\")\n        out_stats = os.path.join(gen_dir, \"gen_stats.txt\")\n        if not (os.path.exists(orig_path) and os.path.exists(gen_path)):\n            continue\n        if os.path.exists(out_stats) and not overwrite_eval:\n            continue\n\n        env = os.environ.copy()\n        env[\"PYTHONPATH\"] = REPO + (\":\" + env.get(\"PYTHONPATH\",\"\") if env.get(\"PYTHONPATH\") else \"\")\n        cmd = [\n            _sys.executable, \"-m\", \"evaluation.evaluate_all\",\n            \"--orig_path\", orig_path,\n            \"--gen_path\",  gen_path,\n            \"--tox_threshold\", str(tox_threshold),\n            \"--tox_batch_size\", str(tox_batch_size),\n        ]\n        if skip_ref:\n            cmd.append(\"--skip_ref\")\n        print(\"eval:\", \" \".join(cmd))\n        res = run(cmd, cwd=REPO, env=env, stdout=PIPE, stderr=PIPE, text=True)\n        if res.returncode != 0:\n            print(res.stdout)\n            print(res.stderr)\n            res.check_returncode()\n\ndef _safe_float(x):\n    try:\n        return float(x)\n    except Exception:\n        return float('nan')\n\ndef _read_stats_file(path):\n    out = {}\n    with open(path, \"r\") as f:\n        for line in f:\n            if \":\" not in line:\n                continue\n            k, v = line.strip().split(\": \", 1)\n            k = k.replace(\"(skipped)\", \"\").strip().lower()\n            out[k] = _safe_float(v)\n    return out\n\ndef _aggregate_eval_csv(output_folder, data_type, base_out_dir):\n    rows = []\n    for thresh in np.arange(0.15, 0.3, 0.05, dtype=np.float64):\n        mask_dir = f\"DecompX{abs(thresh):g}\" if thresh != 0 else \"DecompX0.0\"\n        base_path = os.path.join(base_out_dir, data_type, mask_dir)\n        if not os.path.isdir(base_path):\n            continue\n        for folder in os.listdir(base_path):\n            gen_dir = os.path.join(base_path, folder)\n            stats_path = os.path.join(gen_dir, \"gen_stats.txt\")\n            if not os.path.exists(stats_path):\n                continue\n            s = _read_stats_file(stats_path)\n            rows.append({\n                \"threshold\":        float(f\"{thresh:.2f}\"),\n                \"folder\":           folder,\n                \"bertscore\":        s.get(\"bertscore\", np.nan),\n                \"meaningbert\":      s.get(\"meaningbert\", np.nan),\n                \"bleu4\":            s.get(\"bleu4\", np.nan),\n                \"perplexity_gen\":   s.get(\"perplexity gen\", np.nan),\n                \"perplexity_orig\":  s.get(\"perplexity orig\", np.nan),\n                \"toxicity_gen\":     s.get(\"toxicity gen\", np.nan),\n                \"toxicity_orig\":    s.get(\"toxicity orig\", np.nan),\n            })\n\n    if rows:\n        cols = [\n            \"threshold\", \"folder\",\n            \"bertscore\", \"meaningbert\", \"bleu4\",\n            \"perplexity_gen\", \"perplexity_orig\",\n            \"toxicity_gen\", \"toxicity_orig\",\n        ]\n        df = pd.DataFrame(rows)\n        df = df[cols]\n        out_csv = os.path.join(base_out_dir, data_type, f\"{data_type}.csv\")\n        df.to_csv(out_csv, index=False)\n        print(\"wrote summary csv:\", out_csv)\n    else:\n        print(\"no evaluation files found.\")",
   "metadata": {
    "id": "ybmqf84duA4a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859428,
     "user_tz": 480,
     "elapsed": 2,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "ybmqf84duA4a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def _process_in_batches(masker, inputs, batch_size, thresh: float):\n    batched_inputs = [\n        inputs[i : i + batch_size] for i in range(0, len(inputs), batch_size)\n    ]\n    results = []\n    for batch in tqdm(batched_inputs, desc=\"masking\", leave=False):\n        batch_result = masker.process_text(sentence=batch, threshold=thresh)\n        results.append(batch_result)\n    return results\n\ndef _bool2str(x: bool) -> str:\n    return \"T\" if x else \"F\"\n\ndef _build_gen_folder_name(\n    alpha_a, alpha_e, alpha_b,\n    base_type, antiexpert_type, expert_type,\n    temperature, sample, top_k_gen, rep_penalty, filter_p, max_length, top_p\n):\n    return (\n        \"aa\" + str(alpha_a) +\n        \"_ae\" + str(alpha_e) +\n        \"_ab\" + str(alpha_b) +\n        \"_base\" + base_type[:5] +\n        \"_anti\" + antiexpert_type[:5] +\n        \"_expert\" + expert_type[:5] +\n        \"_temp\" + str(temperature) +\n        \"_sample\" + _bool2str(sample) +\n        \"_topk\" + str(top_k_gen) +\n        \"_reppenalty\" + str(rep_penalty) +\n        \"_filterp\" + str(filter_p) +\n        \"_maxlength\" + str(max_length) +\n        \"_topp\" + str(top_p)\n    )\n\ndef _run_global_reranking_for_threshold(\n    data_type,\n    subset_path,\n    thresh,\n    base_out_rel,\n    batch_size,\n    alpha_a, alpha_e, alpha_b,\n    temperature,\n    rep_penalty,\n    max_length,\n    top_k_gen,\n    top_p,\n    filter_p,\n    sample,\n    num_candidates,\n    weights,\n    overwrite_gen=False,\n    echo: bool = False,\n    inputs=None,\n):\n    if inputs is None:\n        args_data = _argparse.Namespace(data_type=data_type, data_path=subset_path)\n        inputs = rx.get_data(args_data)\n    print(f\"#inputs at thresh={thresh}: {len(inputs)}\")\n\n    mask_dir = f\"DecompX{abs(thresh):g}\" if thresh != 0 else \"DecompX0.0\"\n    cur_rel = os.path.join(base_out_rel, data_type, mask_dir)\n    cur_abs = os.path.join(REPO, cur_rel)\n    _ensure_dir(cur_abs)\n\n    masked_file = os.path.join(cur_abs, \"masked_inputs.txt\")\n\n    if not os.path.exists(masked_file):\n        masker = Masker_single()\n        decoded_masked_inputs_batches = _process_in_batches(\n            masker, inputs, batch_size=batch_size, thresh=thresh\n        )\n        decoded_masked_inputs = [\n            item for sublist in decoded_masked_inputs_batches for item in sublist\n        ]\n        decoded_mask_inputs = [\n            d.replace(\"<s>\", \"\").replace(\"</s>\", \"\") for d in decoded_masked_inputs\n        ]\n        with open(masked_file, \"w\") as f:\n            for d in decoded_mask_inputs:\n                f.write(re.sub(r\"\\s+\", \" \", d) + \"\\n\")\n        masker.release_model()\n    else:\n        with open(masked_file, \"r\") as f:\n            decoded_mask_inputs = [s.strip() for s in f.readlines()]\n        print(\"reusing existing masked_inputs.txt\")\n\n    assert len(decoded_mask_inputs) == len(inputs), \"Masked vs inputs mismatch\"\n\n    if echo:\n        print(f\"\\nexample masked inputs at threshold {thresh:.2f} (first up to 3):\")\n        for i, m in enumerate(decoded_mask_inputs[:3]):\n            print(f\"  masked[{i}]: {m}\")\n\n    rewriter = Infiller(\n        seed=0,\n        base_path=\"facebook/bart-base\",\n        antiexpert_path=\"hallisky/bart-base-toxic-antiexpert\",\n        expert_path=\"hallisky/bart-base-nontoxic-expert\",\n        base_type=\"base\",\n        antiexpert_type=\"antiexpert\",\n        expert_type=\"expert\",\n        tokenizer=\"facebook/bart-base\",\n    )\n\n    base_type = \"base\"\n    antiexpert_type = \"antiexpert\"\n    expert_type = \"expert\"\n    gen_folder = _build_gen_folder_name(\n        alpha_a, alpha_e, alpha_b,\n        base_type, antiexpert_type, expert_type,\n        temperature, sample, top_k_gen, rep_penalty, filter_p, max_length, top_p\n    )\n    final_abs = os.path.join(cur_abs, gen_folder)\n    gen_txt = os.path.join(final_abs, \"gen.txt\")\n    orig_txt = os.path.join(final_abs, \"orig.txt\")\n\n    if os.path.exists(gen_txt) and not overwrite_gen:\n        print(\"generation already exists at:\", gen_txt)\n        return\n\n    _ensure_dir(final_abs)\n\n    all_candidates: List[List[str]] = [[] for _ in range(len(inputs))]\n\n    print(f\"generating {num_candidates} candidates per input (sampling={sample})\")\n    for c in range(num_candidates):\n        outs, decoded = rewriter.generate(\n            inputs,\n            decoded_mask_inputs,\n            alpha_a=alpha_a,\n            alpha_e=alpha_e,\n            alpha_b=alpha_b,\n            temperature=temperature,\n            verbose=False,\n            max_length=max_length,\n            repetition_penalty=rep_penalty,\n            p=top_p,\n            filter_p=filter_p,\n            k=top_k_gen,\n            batch_size=batch_size,\n            sample=sample,\n            ranking=False,\n            ranking_eval_output=0,\n        )\n        for i, text in enumerate(decoded):\n            all_candidates[i].append(re.sub(r\"\\s+\", \" \", text).strip())\n\n    del rewriter\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n    print(\"global reranking (toxicity + similarity + fluency)...\")\n    best_idx, details = rerank_candidates_global(\n        sources=inputs,\n        candidates=all_candidates,\n        weights=weights,\n    )\n    best_generations = [\n        all_candidates[i][best_idx[i]] for i in range(len(inputs))\n    ]\n\n    if echo:\n        print(f\"\\nexample detoxified outputs at threshold {thresh:.2f} (first up to 3):\")\n        for i, g in enumerate(best_generations[:3]):\n            print(f\"  detox[{i}]: {g}\")\n\n    with open(orig_txt, \"w\") as f:\n        for l in inputs:\n            f.write(re.sub(r\"\\s+\", \" \", l).strip() + \"\\n\")\n    with open(gen_txt, \"w\") as f:\n        for l in best_generations:\n            f.write(re.sub(r\"\\s+\", \" \", l).strip() + \"\\n\")\n\n    print(\"saved:\", orig_txt)\n    print(\"saved:\", gen_txt)",
   "metadata": {
    "id": "U5oOUWRYuA6E",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859432,
     "user_tz": 480,
     "elapsed": 2,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "U5oOUWRYuA6E",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def detoxify(\n    data_type: str = \"paradetox\",\n    output_folder: str = \"colab_run_global\",\n    thresholds = (0.15, 0.20, 0.25),\n    echo: bool = False,\n    batch_size: int = 10,\n    sample: bool = True,\n    top_k_gen: int = 50,\n    top_p: float = 0.95,\n    filter_p: float = 1.0,\n    max_length: int = 128,\n    alpha_a: float = None,\n    alpha_e: float = None,\n    alpha_b: float = 1.0,\n    temperature: float = None,\n    rep_penalty: float = None,\n    num_examples: int = 100,\n    overwrite_gen: bool = False,\n    run_eval: bool = False,\n    overwrite_eval: bool = False,\n    skip_ref_eval: bool = False,\n    weights = (0.5, 0.3, 0.2),\n    num_candidates: int = 3,\n):\n    assert data_type in data_configs, f\"Unknown data_type: {data_type}\"\n    cfg = data_configs[data_type].copy()\n\n    if num_candidates < 1:\n        raise ValueError(\"num_candidates must be >= 1\")\n\n    if alpha_a is None:\n        alpha_a = cfg[\"alpha_a\"]\n    if alpha_e is None:\n        alpha_e = cfg[\"alpha_e\"]\n    if temperature is None:\n        temperature = cfg[\"temperature\"]\n    if rep_penalty is None:\n        rep_penalty = cfg[\"rep_penalty\"]\n\n    base_out_rel = os.path.join(\"data\", \"model_outputs\", output_folder)\n    base_out_abs = os.path.join(REPO, base_out_rel)\n    _ensure_dir(base_out_abs)\n\n    original_data_path = cfg[\"data_path\"]\n    subset_dir = os.path.join(REPO, \"datasets\", \"_subsets\", data_type)\n    _ensure_dir(subset_dir)\n    subset_path = _subset_for_data_type(\n        data_type, original_data_path, num_examples, subset_dir\n    )\n\n    args_data = _argparse.Namespace(data_type=data_type, data_path=subset_path)\n    inputs = rx.get_data(args_data)\n    num_inputs = len(inputs)\n\n    if echo:\n        print(\"=\" * 80)\n        print(f\"dataset: {data_type}\")\n        print(f\"subset path: {subset_path}\")\n        print(f\"output base: {base_out_abs}\")\n        print(f\"number of examples to detoxify: {num_inputs}\")\n        print(f\"thresholds: {', '.join(f'{t:.2f}' for t in thresholds)}\")\n        print(f\"Weights (w_T, w_S, w_F): {weights}\")\n        print(f\"num_candidates per input: {num_candidates}\")\n        print(\"\\nexample inputs (first up to 3):\")\n        for i, s in enumerate(inputs[:3]):\n            print(f\"  input[{i}]: {s}\")\n        print(\"=\" * 80)\n\n    for t in thresholds:\n        print(\"=\" * 60)\n        print(f\"threshold (decompx) = {t:.2f}\")\n        _run_global_reranking_for_threshold(\n            data_type=data_type,\n            subset_path=subset_path,\n            thresh=t,\n            base_out_rel=base_out_rel,\n            batch_size=batch_size,\n            alpha_a=alpha_a,\n            alpha_e=alpha_e,\n            alpha_b=alpha_b,\n            temperature=temperature,\n            rep_penalty=rep_penalty,\n            max_length=max_length,\n            top_k_gen=top_k_gen,\n            top_p=top_p,\n            filter_p=filter_p,\n            sample=sample,\n            num_candidates=num_candidates,\n            weights=weights,\n            overwrite_gen=overwrite_gen,\n            echo=echo,\n            inputs=inputs,\n        )\n\n        if run_eval:\n            mask_dir = f\"DecompX{abs(t):g}\" if t != 0 else \"DecompX0.0\"\n            base_path = os.path.join(base_out_abs, data_type, mask_dir)\n            _eval_with_toxicity(\n                base_path,\n                overwrite_eval=overwrite_eval,\n                skip_ref=skip_ref_eval,\n                tox_threshold=0.5,\n                tox_batch_size=32,\n            )\n\n            if echo:\n                base_type = \"base\"\n                antiexpert_type = \"antiexpert\"\n                expert_type = \"expert\"\n                gen_folder = _build_gen_folder_name(\n                    alpha_a, alpha_e, alpha_b,\n                    base_type, antiexpert_type, expert_type,\n                    temperature, sample, top_k_gen, rep_penalty, filter_p, max_length, top_p\n                )\n                stats_path = os.path.join(base_path, gen_folder, \"gen_stats.txt\")\n                if os.path.exists(stats_path):\n                    stats = _read_stats_file(stats_path)\n                    print(f\"\\nevaluation metrics for this run (t={t:.2f}):\")\n                    metric_keys = [\n                        (\"bertscore\",        \"bertscore\"),\n                        (\"meaningbert\",      \"meaningbert\"),\n                        (\"bleu4\",            \"bleu-4\"),\n                        (\"perplexity gen\",   \"perplexity (gen)\"),\n                        (\"perplexity orig\",  \"perplexity (orig)\"),\n                        (\"toxicity gen\",     \"toxicity (gen)\"),\n                        (\"toxicity orig\",    \"toxicity (orig)\"),\n                    ]\n                    for key, label in metric_keys:\n                        val = stats.get(key, None)\n                        if isinstance(val, float) and math.isnan(val):\n                            continue\n                        if val is None:\n                            continue\n                        print(f\"  {label}: {val:.4f}\")\n                else:\n                    print(f\"gen_stats.txt not found at {stats_path}\")\n\n    if run_eval:\n        _aggregate_eval_csv(\n            output_folder,\n            data_type,\n            os.path.join(REPO, \"data\", \"model_outputs\", output_folder),\n        )",
   "metadata": {
    "id": "oqBLx5OSuA72",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859449,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "oqBLx5OSuA72",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# detoxify(\n#     data_type=\"paradetox\",\n#     output_folder=\"colab_run_global_demo\",\n#     thresholds=(0.20,),\n#     batch_size=8,\n#     sample=True,\n#     top_k_gen=50,\n#     top_p=0.95,\n#     max_length=96,\n#     num_examples=50,\n#     run_eval=True,\n#     overwrite_gen=True,\n#     overwrite_eval=True,\n#     skip_ref_eval=False,\n#     weights=(0.5, 0.3, 0.2),\n#     num_candidates=20,\n# )\n",
   "metadata": {
    "id": "u5LlySYquA9g",
    "collapsed": true,
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764461859464,
     "user_tz": 480,
     "elapsed": 13,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    }
   },
   "id": "u5LlySYquA9g",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "detoxify(\n",
    "    data_type=\"paradetox\",\n",
    "    output_folder=\"XDetox_w_DecompX-Masking-Global-Reranking_Pipeline\",\n",
    "    thresholds=(0.20,),\n",
    "    echo=True,\n",
    "    batch_size=8,\n",
    "    sample=True,\n",
    "    top_k_gen=50,\n",
    "    top_p=0.95,\n",
    "    max_length=96,\n",
    "    num_examples=1000,\n",
    "    run_eval=True,\n",
    "    overwrite_gen=True,\n",
    "    overwrite_eval=True,\n",
    "    skip_ref_eval=False,\n",
    "    weights=(0.5, 0.3, 0.2),\n",
    "    num_candidates=10,\n",
    ")"
   ],
   "metadata": {
    "id": "VgZRbEBED8w4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c565bf76a1604f29a356f164ed4f4df2",
      "3f49d34a609145b58b0a87bc7bc9f9a4",
      "3b736fc178ae46dbb44bf0cf17c28b83",
      "d4d1451fb6734a04a16016e3b3229026",
      "d49621662fe94cb1bca3d1f002c00bae",
      "e3af145e36a04c4db08d6e1cbf4dec00",
      "d032619d44114f508e22e299f9eea8ec",
      "8696f377b949496f84596040048c56d7",
      "858fa9e4ed984d30803b3c490edb48df",
      "a137655c3aaf460e8665a7fc7b6c40f9",
      "a4c1126925364ba4a90f1c5278a985c1",
      "e2d84a3ad5b5452c81d5e5f051b66204",
      "6aedafc5c3894191bbe012b0c53e17b1",
      "a0a6a9725ba44fb7a741a43928bcd282",
      "95e1fa39225c42a89b1c7d9710568009",
      "ba9947b230e24502b9ea4d35662edcc4",
      "5a1e1ca5651749dbab65d3e5aecc4064",
      "9a5d0ab188d54f1f88a60fb18f386aea",
      "06d320a128c94dc7abddb9edbf318a09",
      "df8bca7348204c968bb43b3f0fe87dfc",
      "5c3ff9a305ca433283ba4b9bf9046afb",
      "dd1cad3cec8c44c596b3abc418eaa33d",
      "d60a172720aa45dcbb2e388bf245b377",
      "cbef5340483e462b80b6ac21a38f8eb3",
      "0fa4795963bb4370a81fdf8a389a183f",
      "22c99935e46046d2a5da148a99da69f2",
      "746fa324d55d453fb7ec000b6c12624e",
      "810d06f870724cf09debed49b872dcfa",
      "31f5644ea5f3495bb7b638d34ed0ec0c",
      "d891620b009b46aaadd17efb00c2cf0a",
      "ab153c6f7a484db99c26e01eebdb61aa",
      "e7fa49154fe24b878558e508ff002cee",
      "2ad62031ee224e819540d1eb4971ba5d",
      "c5033717aa9b4c868a87a2521380a850",
      "06b5b10c94ed402fae2a2b4ca4bc8202",
      "a22ca9141280424c919ea7a725168237",
      "02b7af9a664b425aacd142021621e3f6",
      "ea3a9701612d4c8fa9ca6c23a2c89605",
      "e82bc5362bde4e91b3bf6e4270ce497f",
      "37d74e5b45dc4b04ab1153fe27f16ece",
      "62316a1944e44d9a8d80c5fb7196eca3",
      "0a62b792ffe94b53a4e90af3111eaf31",
      "2a7d68cf41fd476b9f0e7d712efd1e56",
      "b8dd9686bb274b37a509c5136edfb88a",
      "22dffbfb44c345cbab9b9ac3ab12bfb7",
      "420f3592de454d7f8a03ee4ec1a6ca29",
      "5f7e7983e90d40f9a148a7fc34e58aeb",
      "ca91e7b162814ebab7fb63152bb79e05",
      "c03e52f3fa8b4c00badaaf930fb64e36",
      "863987c418a847c68955a425332e039c",
      "c4d3c4c6692d49e7ae373e71843cc14d",
      "178e9d9b6b8e4a8099ba9688defca7de",
      "c3ebc9853c54487cac6b1f33827720b3",
      "2d96ea407919429ebe8e5c2e73e97bb0",
      "8dbf0e978c274ddea7ea0e9a475d080e"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764463634687,
     "user_tz": 480,
     "elapsed": 1775220,
     "user": {
      "displayName": "Kent Bourgoing",
      "userId": "01773768369839516808"
     }
    },
    "outputId": "6a784868-6589-4bd4-a12b-6f56faf766dd"
   },
   "id": "VgZRbEBED8w4",
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================================================================\n",
      "[echo] Dataset: paradetox\n",
      "[echo] Subset path: /content/drive/MyDrive/w266 - Project/XDetox/datasets/_subsets/paradetox/test_toxic_parallel.txt\n",
      "[echo] Output base: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-Global-Reranking_Pipeline\n",
      "[echo] Number of examples to detoxify: 671\n",
      "[echo] Thresholds: 0.20\n",
      "[echo] Weights (w_T, w_S, w_F): (0.5, 0.3, 0.2)\n",
      "[echo] num_candidates per input: 10\n",
      "\n",
      "[echo] Example inputs (first up to 3):\n",
      "  input[0]: . or the loud ass one - thousand ton beast roaring towards you howling its horn .\n",
      "  input[1]: mandated  and \" right fucking now \" would be good .\n",
      "  input[2]: * neither * of my coworkers gave a shit when it came time to ditch mitch . ugh .\n",
      "================================================================================\n",
      "============================================================\n",
      "Threshold (DecompX) = 0.20\n",
      "#inputs at thresh=0.2: 671\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Masking (DecompX):   0%|          | 0/84 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c565bf76a1604f29a356f164ed4f4df2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1052: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[echo] Example masked inputs at threshold 0.20 (first up to 3):\n",
      "  masked[0]: . or the loud <mask> one - thousand ton beast roaring towards you howling its horn .\n",
      "  masked[1]: mandated  and \" right <mask> now \" would be good .\n",
      "  masked[2]: * neither * of my coworkers gave a <mask> when it came time to ditch mitch . ugh .\n",
      "Found 1 GPUS!\n",
      "Generating 10 candidates per input (sampling=True)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Filling in masks: 100%|██████████| 84/84 [01:30<00:00,  1.08s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:30<00:00,  1.08s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:36<00:00,  1.15s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:34<00:00,  1.13s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:37<00:00,  1.17s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:26<00:00,  1.03s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:37<00:00,  1.16s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:42<00:00,  1.22s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:34<00:00,  1.12s/it]\n",
      "Filling in masks: 100%|██████████| 84/84 [01:28<00:00,  1.06s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Global reranking (toxicity + similarity + fluency)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Toxicity:   0%|          | 0/210 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2d84a3ad5b5452c81d5e5f051b66204"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "LaBSE embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d60a172720aa45dcbb2e388bf245b377"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "LaBSE embeddings:   0%|          | 0/210 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5033717aa9b4c868a87a2521380a850"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "GPT-2 PPL:   0%|          | 0/6710 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22dffbfb44c345cbab9b9ac3ab12bfb7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[echo] Example detoxified outputs at threshold 0.20 (first up to 3):\n",
      "  detox[0]: . or the loud sound of a one- thousand ton beast roaring towards you howling its horn.\n",
      "  detox[1]: mandated and \"right now\" would be good.\n",
      "  detox[2]: *nor* of my coworkers gave a hoot about the fact that they were all over the place when it came time to ditch mitch. ugh.\n",
      "Saved: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-Global-Reranking_Pipeline/paradetox/DecompX0.2/aa1.5_ae4.75_ab1.0_basebase_antiantie_expertexper_temp2.5_sampleT_topk50_reppenalty1.0_filterp1.0_maxlength96_topp0.95/orig.txt\n",
      "Saved: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-Global-Reranking_Pipeline/paradetox/DecompX0.2/aa1.5_ae4.75_ab1.0_basebase_antiantie_expertexper_temp2.5_sampleT_topk50_reppenalty1.0_filterp1.0_maxlength96_topp0.95/gen.txt\n",
      "Eval: /usr/bin/python3 -m evaluation.evaluate_all --orig_path /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-Global-Reranking_Pipeline/paradetox/DecompX0.2/aa1.5_ae4.75_ab1.0_basebase_antiantie_expertexper_temp2.5_sampleT_topk50_reppenalty1.0_filterp1.0_maxlength96_topp0.95/orig.txt --gen_path /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-Global-Reranking_Pipeline/paradetox/DecompX0.2/aa1.5_ae4.75_ab1.0_basebase_antiantie_expertexper_temp2.5_sampleT_topk50_reppenalty1.0_filterp1.0_maxlength96_topp0.95/gen.txt --tox_threshold 0.5 --tox_batch_size 32\n",
      "\n",
      "[echo] Evaluation metrics for this run (t=0.20):\n",
      "  BERTScore: 0.9440\n",
      "  MeaningBERT: 72.7220\n",
      "  BLEU-4: 70.0470\n",
      "  Perplexity (gen): 124.9500\n",
      "  Perplexity (orig): 273.7500\n",
      "  Toxicity (gen): 0.1201\n",
      "  Toxicity (orig): 0.9253\n",
      "Wrote summary CSV: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-Global-Reranking_Pipeline/paradetox/paradetox.csv\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c565bf76a1604f29a356f164ed4f4df2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f49d34a609145b58b0a87bc7bc9f9a4",
       "IPY_MODEL_3b736fc178ae46dbb44bf0cf17c28b83",
       "IPY_MODEL_d4d1451fb6734a04a16016e3b3229026"
      ],
      "layout": "IPY_MODEL_d49621662fe94cb1bca3d1f002c00bae"
     }
    },
    "3f49d34a609145b58b0a87bc7bc9f9a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3af145e36a04c4db08d6e1cbf4dec00",
      "placeholder": "​",
      "style": "IPY_MODEL_d032619d44114f508e22e299f9eea8ec",
      "value": "Masking (DecompX):  99%"
     }
    },
    "3b736fc178ae46dbb44bf0cf17c28b83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8696f377b949496f84596040048c56d7",
      "max": 84,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_858fa9e4ed984d30803b3c490edb48df",
      "value": 84
     }
    },
    "d4d1451fb6734a04a16016e3b3229026": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a137655c3aaf460e8665a7fc7b6c40f9",
      "placeholder": "​",
      "style": "IPY_MODEL_a4c1126925364ba4a90f1c5278a985c1",
      "value": " 83/84 [00:06&lt;00:00, 14.82it/s]"
     }
    },
    "d49621662fe94cb1bca3d1f002c00bae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e3af145e36a04c4db08d6e1cbf4dec00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d032619d44114f508e22e299f9eea8ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8696f377b949496f84596040048c56d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "858fa9e4ed984d30803b3c490edb48df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a137655c3aaf460e8665a7fc7b6c40f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c1126925364ba4a90f1c5278a985c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2d84a3ad5b5452c81d5e5f051b66204": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6aedafc5c3894191bbe012b0c53e17b1",
       "IPY_MODEL_a0a6a9725ba44fb7a741a43928bcd282",
       "IPY_MODEL_95e1fa39225c42a89b1c7d9710568009"
      ],
      "layout": "IPY_MODEL_ba9947b230e24502b9ea4d35662edcc4"
     }
    },
    "6aedafc5c3894191bbe012b0c53e17b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a1e1ca5651749dbab65d3e5aecc4064",
      "placeholder": "​",
      "style": "IPY_MODEL_9a5d0ab188d54f1f88a60fb18f386aea",
      "value": "Toxicity: 100%"
     }
    },
    "a0a6a9725ba44fb7a741a43928bcd282": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06d320a128c94dc7abddb9edbf318a09",
      "max": 210,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df8bca7348204c968bb43b3f0fe87dfc",
      "value": 210
     }
    },
    "95e1fa39225c42a89b1c7d9710568009": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c3ff9a305ca433283ba4b9bf9046afb",
      "placeholder": "​",
      "style": "IPY_MODEL_dd1cad3cec8c44c596b3abc418eaa33d",
      "value": " 209/210 [00:08&lt;00:00, 26.94it/s]"
     }
    },
    "ba9947b230e24502b9ea4d35662edcc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "5a1e1ca5651749dbab65d3e5aecc4064": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a5d0ab188d54f1f88a60fb18f386aea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06d320a128c94dc7abddb9edbf318a09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df8bca7348204c968bb43b3f0fe87dfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c3ff9a305ca433283ba4b9bf9046afb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd1cad3cec8c44c596b3abc418eaa33d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d60a172720aa45dcbb2e388bf245b377": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbef5340483e462b80b6ac21a38f8eb3",
       "IPY_MODEL_0fa4795963bb4370a81fdf8a389a183f",
       "IPY_MODEL_22c99935e46046d2a5da148a99da69f2"
      ],
      "layout": "IPY_MODEL_746fa324d55d453fb7ec000b6c12624e"
     }
    },
    "cbef5340483e462b80b6ac21a38f8eb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_810d06f870724cf09debed49b872dcfa",
      "placeholder": "​",
      "style": "IPY_MODEL_31f5644ea5f3495bb7b638d34ed0ec0c",
      "value": "LaBSE embeddings:  95%"
     }
    },
    "0fa4795963bb4370a81fdf8a389a183f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d891620b009b46aaadd17efb00c2cf0a",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab153c6f7a484db99c26e01eebdb61aa",
      "value": 21
     }
    },
    "22c99935e46046d2a5da148a99da69f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7fa49154fe24b878558e508ff002cee",
      "placeholder": "​",
      "style": "IPY_MODEL_2ad62031ee224e819540d1eb4971ba5d",
      "value": " 20/21 [00:00&lt;00:00, 63.21it/s]"
     }
    },
    "746fa324d55d453fb7ec000b6c12624e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "810d06f870724cf09debed49b872dcfa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31f5644ea5f3495bb7b638d34ed0ec0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d891620b009b46aaadd17efb00c2cf0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab153c6f7a484db99c26e01eebdb61aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7fa49154fe24b878558e508ff002cee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ad62031ee224e819540d1eb4971ba5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5033717aa9b4c868a87a2521380a850": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06b5b10c94ed402fae2a2b4ca4bc8202",
       "IPY_MODEL_a22ca9141280424c919ea7a725168237",
       "IPY_MODEL_02b7af9a664b425aacd142021621e3f6"
      ],
      "layout": "IPY_MODEL_ea3a9701612d4c8fa9ca6c23a2c89605"
     }
    },
    "06b5b10c94ed402fae2a2b4ca4bc8202": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e82bc5362bde4e91b3bf6e4270ce497f",
      "placeholder": "​",
      "style": "IPY_MODEL_37d74e5b45dc4b04ab1153fe27f16ece",
      "value": "LaBSE embeddings:  97%"
     }
    },
    "a22ca9141280424c919ea7a725168237": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62316a1944e44d9a8d80c5fb7196eca3",
      "max": 210,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a62b792ffe94b53a4e90af3111eaf31",
      "value": 210
     }
    },
    "02b7af9a664b425aacd142021621e3f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a7d68cf41fd476b9f0e7d712efd1e56",
      "placeholder": "​",
      "style": "IPY_MODEL_b8dd9686bb274b37a509c5136edfb88a",
      "value": " 203/210 [00:02&lt;00:00, 77.43it/s]"
     }
    },
    "ea3a9701612d4c8fa9ca6c23a2c89605": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e82bc5362bde4e91b3bf6e4270ce497f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37d74e5b45dc4b04ab1153fe27f16ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62316a1944e44d9a8d80c5fb7196eca3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a62b792ffe94b53a4e90af3111eaf31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a7d68cf41fd476b9f0e7d712efd1e56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8dd9686bb274b37a509c5136edfb88a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22dffbfb44c345cbab9b9ac3ab12bfb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_420f3592de454d7f8a03ee4ec1a6ca29",
       "IPY_MODEL_5f7e7983e90d40f9a148a7fc34e58aeb",
       "IPY_MODEL_ca91e7b162814ebab7fb63152bb79e05"
      ],
      "layout": "IPY_MODEL_c03e52f3fa8b4c00badaaf930fb64e36"
     }
    },
    "420f3592de454d7f8a03ee4ec1a6ca29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_863987c418a847c68955a425332e039c",
      "placeholder": "​",
      "style": "IPY_MODEL_c4d3c4c6692d49e7ae373e71843cc14d",
      "value": "GPT-2 PPL: 100%"
     }
    },
    "5f7e7983e90d40f9a148a7fc34e58aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_178e9d9b6b8e4a8099ba9688defca7de",
      "max": 6710,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3ebc9853c54487cac6b1f33827720b3",
      "value": 6710
     }
    },
    "ca91e7b162814ebab7fb63152bb79e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d96ea407919429ebe8e5c2e73e97bb0",
      "placeholder": "​",
      "style": "IPY_MODEL_8dbf0e978c274ddea7ea0e9a475d080e",
      "value": " 6706/6710 [01:15&lt;00:00, 90.05it/s]"
     }
    },
    "c03e52f3fa8b4c00badaaf930fb64e36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "863987c418a847c68955a425332e039c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4d3c4c6692d49e7ae373e71843cc14d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "178e9d9b6b8e4a8099ba9688defca7de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3ebc9853c54487cac6b1f33827720b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2d96ea407919429ebe8e5c2e73e97bb0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dbf0e978c274ddea7ea0e9a475d080e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}